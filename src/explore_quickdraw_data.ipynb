{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-german",
   "metadata": {},
   "source": [
    "# from np bitmap\n",
    "\n",
    "https://medium.com/tensorflow/train-on-google-colab-and-run-on-the-browser-a-case-study-8a45f9b1474e\n",
    "\n",
    "data from: \n",
    "https://github.com/googlecreativelab/quickdraw-dataset#get-the-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "file = '../../../../Downloads/full_numpy_bitmap_sheep.npy'\n",
    "class_name, ext = os.path.splitext(os.path.basename(file))\n",
    "\n",
    "sheep = np.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-trainer",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "from IPython.display import display, clear_output\n",
    "count = 0\n",
    "width=28\n",
    "height=28\n",
    "zoom=1\n",
    "for s in sheep: \n",
    "    clear_output(wait=True)\n",
    "    count += 1\n",
    "    a = s.reshape(28,28)\n",
    "\n",
    "    f_img = Image.fromarray(a)\n",
    "    img = PIL.ImageOps.invert(f_img)\n",
    "    display(img.resize((zoom*width, zoom*height), Image.BICUBIC, reducing_gap=3))\n",
    "    time.sleep(.5)\n",
    "    if count == 20: \n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "\n",
    "img = imshow(a)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-posting",
   "metadata": {},
   "source": [
    "## data from quickdraw lib\n",
    "https://quickdraw.readthedocs.io/en/latest/index.html\n",
    "\n",
    "\n",
    "RGB to grey\n",
    "\n",
    "https://stackoverflow.com/questions/41966514/how-fast-in-python-change-3-channel-rgb-color-image-to-1-channel-gray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "import quickdraw as qd\n",
    "\n",
    "qd_data = qd.QuickDrawData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-battle",
   "metadata": {},
   "outputs": [],
   "source": [
    "qd_data.drawing_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheep = qd.QuickDrawDataGroup('sheep', recognized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheep.drawing_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-assessment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-hearing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sheep1 = sheep.get_drawing(0)\n",
    "img = sheep1.image\n",
    "\n",
    "img\n",
    "img = img.crop()\n",
    "img\n",
    "a = np.array(img)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "width=28\n",
    "height=28\n",
    "zoom=1\n",
    "for idx in list(range(sheep.drawing_count)): \n",
    "\n",
    "    clear_output(wait=True)\n",
    "    count += 1\n",
    "    \n",
    "    drawing = sheep.get_drawing(idx)\n",
    "    img = drawing.image\n",
    "    if False: \n",
    "        a = s.reshape(28,28)\n",
    "\n",
    "        f_img = Image.fromarray(a)\n",
    "        img = PIL.ImageOps.invert(f_img)\n",
    "        display(img.resize((zoom*width, zoom*height), Image.BICUBIC, reducing_gap=3))\n",
    "    \n",
    "    display(img)\n",
    "    time.sleep(.5)\n",
    "    if count == 20: \n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-agreement",
   "metadata": {},
   "source": [
    "## data from quickdraw10 lib\n",
    "\n",
    "https://colab.research.google.com/github/zaidalyafeai/Notebooks/blob/master/QuickDraw10.ipynb#scrollTo=6o30ipBPAQ5Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-worship",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "brief-roman",
   "metadata": {},
   "source": [
    "## ndjson to svg\n",
    "https://pypi.org/project/ndjsonTosvg/\n",
    "\n",
    "https://github.com/thompson318/ndjsonTosvg/blob/master/ndjsontosvg/ui/ndjsontosvg_command_line.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-sentence",
   "metadata": {},
   "source": [
    "## ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "from random import sample, seed\n",
    "from shutil import rmtree\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_path = '../data/'\n",
    "npy_path = os.path.join(data_path, 'npy/')\n",
    "train_path = os.path.join(data_path, 'train/')\n",
    "test_path = os.path.join(data_path, 'test/')\n",
    "\n",
    "for d in [data_path, npy_path, train_path, test_path]: \n",
    "    if not os.path.exists(d): \n",
    "        os.mkdir(d)\n",
    "    \n",
    "def download(class_name, target_path=npy_path):\n",
    "    # https://medium.com/tensorflow/train-on-google-colab-and-run-on-the-browser-a-case-study-8a45f9b1474e\n",
    "    base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
    "    cls_url = class_name.replace('_', '%20')\n",
    "    path = base+cls_url+'.npy'\n",
    "    print(path)\n",
    "    path, _ = urllib.request.urlretrieve(path, os.path.join(npy_path, f'{class_name}.npy'))\n",
    "    return path\n",
    "\n",
    "\n",
    "def save_pngs(a, path): \n",
    "    if not os.path.exists(path): \n",
    "        os.mkdir(path)\n",
    "    else: \n",
    "        rmtree(path)\n",
    "        os.mkdir(path)\n",
    "\n",
    "    for idx, aa in enumerate(a): \n",
    "        f_img = Image.fromarray(aa.reshape(28,28))\n",
    "        f_img.save(os.path.join(path, f'{idx}.png'))\n",
    "\n",
    "\n",
    "def reshape_1d(a_1d, class_name): \n",
    "    x_train_4d = a_1d.reshape(a_1d.shape[0], 28,28,1)\n",
    "\n",
    "    labels = np.full(a_1d.shape[0], class_name)\n",
    "\n",
    "\n",
    "\n",
    "    #x_train_4d = x_train.reshape(x_train.shape[0], 28,28,1)\n",
    "    #x_train_comb = np.concatenate((x_train_comb, x_train_4d), axis=0) \n",
    "\n",
    "    #labels = np.full(x_train.shape[0], cl)\n",
    "    #y_train = np.append(y, labels)\n",
    "\n",
    "    return x_train_4d, labels\n",
    "\n",
    "\n",
    "def to_img(array_4d): \n",
    "    fft_p = array_4d.reshape(28,28)\n",
    "    new_p = Image.fromarray(fft_p)\n",
    "    if new_p.mode != 'RGB':\n",
    "        new_p = new_p.convert('RGB')\n",
    "    return new_p\n",
    "\n",
    "def prepare_imgs_for_generator(classes, test_ratio, max_imgs_per_class, mode='array'): \n",
    "    seed(999)\n",
    "    train_size = None\n",
    "    \n",
    "    if mode not in ['array', 'dir']: \n",
    "        raise ValueError\n",
    "\n",
    "\n",
    "    x_train = np.empty([0, 28,28, 1])\n",
    "    y_train = np.empty([0])\n",
    "    x_test = np.empty([0, 28,28, 1])\n",
    "    y_test = np.empty([0])\n",
    "    class_names = {}\n",
    "    \n",
    "    for cl_idx, cl in enumerate(classes):\n",
    "        print('*'*100)\n",
    "        print(f'processing class **{cl}**' )\n",
    "        file_name = f'{cl}.npy'\n",
    "        source_path = npy_path\n",
    "\n",
    "        if file_name not in os.listdir(source_path): \n",
    "            print(f'download dara to {source_path}')\n",
    "            tmp_path = download(cl, source_path)\n",
    "        else: \n",
    "            print(f'loading data from buffer: {source_path}')\n",
    "            tmp_path = os.path.join(source_path, file_name)\n",
    "        x = np.load(tmp_path)\n",
    "        print('Shape of raw data: ',x.shape)\n",
    "\n",
    "        if max_imgs_per_class is not None: \n",
    "            rand_idx = sample([i for i in range(x.shape[0])], max_imgs_per_class)\n",
    "            x = x[rand_idx, :]\n",
    "\n",
    "        # stratify: memorize abs train size of first class\n",
    "        if train_size is None:    \n",
    "            train_size =  int(x.shape[0]*(1-test_ratio))\n",
    "\n",
    "        # split array into train and test\n",
    "        x_train_1d = x[0:train_size, :]\n",
    "        x_test_1d = x[train_size:x.shape[0], :]\n",
    "        print(f'Shape after sampling, shuffle and first split: train: {x_train_1d.shape} | test: {x_test_1d.shape}')\n",
    "\n",
    "\n",
    "        if mode == 'dir': \n",
    "            # save pngs to disk\n",
    "            save_pngs(x_train_1d, os.path.join(train_path, cl))\n",
    "            save_pngs(x_test_1d, os.path.join(test_path, cl))\n",
    "            \n",
    "            return 'ok'\n",
    "        \n",
    "        elif mode == 'array': \n",
    "            \n",
    "            x_train_tmp, y_train_tmp = reshape_1d(x_train_1d, cl_idx)            \n",
    "            x_train = np.concatenate((x_train, x_train_tmp), axis=0) \n",
    "            y_train = np.append(y_train, y_train_tmp)\n",
    "            \n",
    "            x_test_tmp, y_test_tmp = reshape_1d(x_test_1d, cl_idx)\n",
    "            x_test = np.concatenate((x_test, x_test_tmp), axis=0) \n",
    "            y_test = np.append(y_test, y_test_tmp)\n",
    "            \n",
    "            class_names[cl_idx] = cl\n",
    "\n",
    "            \n",
    "    if mode == 'dir': \n",
    "        return 'ok'\n",
    "    elif mode == 'array': \n",
    "        seed(22)\n",
    "        rand_idx = sample([i for i in range(x_train.shape[0])], x_train.shape[0])\n",
    "        \n",
    "        num_classes=len(classes)\n",
    "        y_train = to_categorical(y_train, num_classes)\n",
    "        y_test = to_categorical(y_test, num_classes)\n",
    "        \n",
    "        return x_train[rand_idx], y_train[rand_idx], x_test, y_test, class_names\n",
    "\n",
    "\n",
    "def build_set_generators(classes, max_imgs_per_class=10000, vali_ratio=.2, test_ratio=.2, batch_size=32):\n",
    "\n",
    "    x_train, y_train, x_test, y_test, class_names = prepare_imgs_for_generator(\n",
    "        classes=classes,\n",
    "        test_ratio=test_ratio,\n",
    "        max_imgs_per_class = max_imgs_per_class\n",
    "    )\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        validation_split=vali_ratio) # set validation split\n",
    "\n",
    "\n",
    "    train_generator = train_datagen.flow(\n",
    "        x=x_train, \n",
    "        y=y_train,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        subset='training'\n",
    "    ) # set as training data\n",
    "\n",
    "    validation_generator = train_datagen.flow(\n",
    "        x=x_train, \n",
    "        y=y_train,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        subset='validation') # set as validation data\n",
    "\n",
    "    test_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        validation_split=0.0) # set validation split\n",
    "\n",
    "    test_generator = test_datagen.flow(\n",
    "        x=x_test, \n",
    "        y=y_test,\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size\n",
    "    ) # set as validation data\n",
    "    \n",
    "    return train_generator, validation_generator, test_generator, class_names\n",
    "\n",
    "\n",
    "            \n",
    "big_mamals = [\n",
    "    \"camel\", \"cow\", \"elephant\", \"giraffe\", \"horse\", \n",
    "    \"kangoroo\", \"lion\", \"panda\", \"rhinoceros\", \"tiger\", \"zebra\"\n",
    "]\n",
    "n_classes = 3\n",
    "class_list = big_mamals[0:n_classes]\n",
    "\n",
    "train_generator, validation_generator, test_generator, class_names = build_set_generators(\n",
    "    classes=class_list, \n",
    "    max_imgs_per_class=10000, \n",
    "    vali_ratio=.2, \n",
    "    test_ratio=.2, \n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, MaxPooling2D\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras import layers\n",
    "\n",
    "def define_model(): \n",
    "    # Initialising the CNN\n",
    "    classifier = Sequential()\n",
    "\n",
    "    # Step 1 - Convolution\n",
    "    classifier.add(Conv2D(32, (3, 3), input_shape = (28, 28, 1), activation = 'relu'))\n",
    "\n",
    "    # Step 2 - Pooling\n",
    "    classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "    # Adding a second convolutional layer\n",
    "    classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "    classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "    # Step 3 - Flattening\n",
    "    classifier.add(Flatten())\n",
    "\n",
    "    # Step 4 - Full connection\n",
    "    classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "    classifier.add(Dense(units = 3, activation = 'sigmoid')) \n",
    "    \n",
    "    classifier.compile(optimizer='rmsprop',  \n",
    "          loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return classifier\n",
    "\n",
    "\n",
    "model = define_model()\n",
    "\n",
    "\n",
    "def define_model2(input_shape=x_train.shape[1:], n_classes=n_classes): \n",
    "    # Define model\n",
    "    model = Sequential()\n",
    "    model.add(layers.Convolution2D(16, (3, 3),\n",
    "                            padding='same',\n",
    "                            input_shape=input_shape, activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Convolution2D(32, (3, 3), padding='same', activation= 'relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Convolution2D(64, (3, 3), padding='same', activation= 'relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size =(2,2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(n_classes, activation='softmax')) \n",
    "\n",
    "    # Train model\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['categorical_accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "model = define_model2()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-header",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/\n",
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30)\n",
    "#es = EarlyStopping(monitor='val_categorical_accuracy', mode='max', min_delta=1, verbose=1, patience=3)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.n // batch_size,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.n // batch_size,\n",
    "    epochs = 100,\n",
    "    callbacks=[es]\n",
    ")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-strategy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
